- Generative
  - Discriminative was dominant back then
- Adversarial
  - Generative models w/ discriminative models
  - Min-max process



`z` latent variables, `x` observed variables

$p_{data}(x)\mapsto p_z(z)\mapsto p_g(x)$ using **reconstruction** loss to fit the distribution

What's problem?

- Elements (e.g. pixels) are **independently** distributed (assumption from loss function)
- Each element follows a simple distribution (Gaussian / Bernoulli / ...) (easy for sampling)

- These assumption are too strict for **high-dim** variables. Can we measure the difference between distributions in another way



Representing distribution difference by NNs!



Theoretical Results:

1. For any given G, the optimal D is:
   $$
   D^*_G(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}
   $$

2. With optimal $D_G$, GAN loss is Jensen-Shannon divergence:
   $$
   L(D^*,G)=2D_{JS}(p_{data}\| p_g)-2\log 2
   $$

3. Global optimality is achieved at $p_g=p_{data}$
   $$
   L(D^*,G^*)=-2\log 2
   $$



Beyond L2/L1, adversarial loss encourages output to look realistic.

Combined with L2/L1, reconstruction loss largely stabilizes training.



Example: Super-resolution GAN. worse PSNR, but better visual quality

Example: Context Encoder (fill holes).

Example: pix2pix limitation: pairs dataset

Example: CycleGAN. How to transfer unpaired data into paired data. Consistency between backgrounds cannot be guaranteed.



Some problem:

1. Difficult to discriminate two distribution. Hard to provide helpful optimization.
2. Mode Collapse. Generator has preference.



Wasserstein GAN

Problem of $D_{JS}$: if $p$ and $q$ don't overlap, $D_{JS}$ is a constant ($\log2$), i.e., no gradient.
$$
W_1(p,q)=\inf_{\gamma\in\prod(p,q)}E_{(x,y)\sim\gamma}|x-y|
$$
Use Kantorovich-Rubinstein Duality:
$$
W_1(p,q)=\frac{1}{K}\sup_{\|f\|_L\leq K} E_{x\sim p} [f(x)] - E_{x\sim q}[f(x)],\quad f\text{ is all K-Lipschitz functions}
$$
W-GAN's objective function:
$$
\max_{w\in W} E_{x\sim p_{data}}[f_w(x)]-E_{x\sim p_g}[f_w(x)]
$$
weights are bounded: in practice, clipped in [-0.01, 0.01].

PGGAN: progressive growing. Large revolution generation.



StyleGAN: SoTA GAN before tokenizers. A style-based Generator Architecture with good editability.

AdaIN: Adaptive instance normalize.

StyleGANv2: Analyses and minor updates. 

StyleGANv3: Alias-Free. 

StyleGAN-XL: + CLF Guidance



GigaGAN: sample-adaptive kernel selection
